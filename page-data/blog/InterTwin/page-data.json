{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/InterTwin/","result":{"data":{"markdownRemark":{"html":"<p>Our  deep learning approach (called InterTwin as a short form for Intersection Twin) uses a large amount of data from different intersection topologies and  signal timing plans, so as to capture the underlying traffic behavior at an intersection. </p>\n<ul>\n<li>We develop a novel two-module deep learning approach that captures the intrinsic properties of traffic behavior at an intersection. The first module corresponds to a spatial graph convolution that is used to extract spatial features from the detector waveforms leveraging the relationship between intersection lanes and signal timing phases. This makes our modeling relatively independent of the intersection topology. The second module is an encoder-decoder with temporal attention architecture, to capture the temporal dynamic behavior of the traffic flow for each phase based on the signal timing plan. These two modules are stacked together for obtaining the final prediction.  </p></li>\n<li>We show that the InterTwin-trained models are able to accurately predict  MOE distributions generated by traffic simulators. After training, when these models are used in inference mode, these models are four to five orders of magnitude faster compared to microscopic simulations. Additionally, it can model multiple intersection topologies without painstakingly redrawing a new base map for each intersection (that is typically required by a microscopic simulator) </p></li>\n<li>For training our models, we use data generated using a significant extension of SUMO~\\cite{SUMO}, an open source microscopic traffic simulator to make the data generation more realistic. We use real-world recorded data from high resolution loop detectors for input traffic patterns. Additionally, we have developed a new module that uses ring and barrier implementation along with arrival and departure information at the advanced and/or stop bar loop detectors along with signal timing information using techniques described in <a href=\"https://ieeexplore.ieee.org/document/9597466\">this work</a> and use them in our simulation to generate high fidelity MOEs that are reflective of data collected from real intersections. Additionally, we suitably vary signal timing parameters for these patterns to generate potentially viable counterfactuals. This results in our methods being able to generalize beyond what is typically used in actual practice and ensures that the models trained can predict robustly for a wide range of signal timing parameters. We also simulate a variety of intersection basemaps and behaviors, and estimate different measures of effectiveness, such as queue lengths, travel times, and wait times. </p></li>\n</ul>","frontmatter":{"title":"InterTwin: Deep Learning Approaches for Computing Measures of Effectiveness for Traffic Intersections","author":"Yashaswi Karnati","date":"13 November, 2021","link":"https://www.mdpi.com/2076-3417/11/24/11637?utm_campaign=releaseissue_applsciutm_medium=emailutm_source=releaseissueutm_term=doilink180","Abstract":"Microscopic simulation-based approaches are extensively used for determining good signal timing plans on traffic intersections. Measures of Effectiveness (MOEs) such as wait time, throughput, fuel consumption, emission, and delays can be derived for variable signal timing parameters, traffic flow patterns, etc. However, these techniques are computationally intensive, especially when the number of signal timing scenarios to be simulated are large. In this paper, we propose InterTwin, a Deep Neural Network architecture based on Spatial Graph Convolution and Encoder-Decoder Recurrent networks that can predict the MOEs efficiently and accurately for a wide variety of signal timing and traffic patterns. Our methods can generate probability distributions of MOEs and are not limited to mean and standard deviation. Additionally, GPU implementations using InterTwin can derive MOEs, at least four to five orders of magnitude faster than microscopic simulations on a conventional 32 core CPU machine.","Published":"Applied Sciences, Special Issue - Machine Learning in Computer Engineering Applications"},"excerpt":"Our  deep learning approach (called InterTwin as a short form for Intersection Twin) uses a large amount of data from different intersectionâ€¦","timeToRead":2}},"pageContext":{"slug":"/blog/InterTwin/","templatePath":"./src/templates/blog-post.js"}},"staticQueryHashes":["3144751780","796719167"]}